{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_Transfer_Learning_Google_Encoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p46w1uzgM8t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f884ffbb-4919-4f5f-df0a-1f97b650c45d"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Version:  2.0.0-rc0\n",
            "Eager mode:  True\n",
            "Hub version:  0.6.0\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXCw_fAgSbyX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "87253d08-6c9a-47f1-f2ca-431ea2c43be4"
      },
      "source": [
        "train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], \n",
        "                                  batch_size=-1, as_supervised=True)\n",
        "\n",
        "train_examples, train_labels = tfds.as_numpy(train_data)\n",
        "test_examples, test_labels = tfds.as_numpy(test_data)\n",
        "\n",
        "# /Users/jheaton/tensorflow_datasets/imdb_reviews/plain_text/0.1.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(), dtype=tf.string),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(), dtype=tf.string),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(), dtype=tf.string),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(), dtype=tf.string),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(), dtype=tf.string),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(), dtype=tf.string),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw2QOPktS2lC",
        "colab_type": "text"
      },
      "source": [
        "%% **Loading the pretrained Google \"gnews\" model which will convert the raw data into 20 dimensional vector **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4rvJNjceZJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
        "hub_layer = hub.KerasLayer(model, output_shape=[20], input_shape=[], \n",
        "                           dtype=tf.string, trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljlu8lo4TRBP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b062a22c-6992-4e42-c969-61ca51548ed9"
      },
      "source": [
        "# Raw training data of the movie review  \n",
        "train_examples[:3]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b\"This was soul-provoking! I am an Iranian, and living in th 21st century, I didn't know that such big tribes have been living in such conditions at the time of my grandfather!<br /><br />You see that today, or even in 1925, on one side of the world a lady or a baby could have everything served for him or her clean and on-demand, but here 80 years ago, people ventured their life to go to somewhere with more grass. It's really interesting that these Persians bear those difficulties to find pasture for their sheep, but they lose many the sheep on their way.<br /><br />I praise the Americans who accompanied this tribe, they were as tough as Bakhtiari people.\",\n",
              "       b'I have no idea what the other reviewer is talking about- this was a wonderful movie, and created a sense of the era that feels like time travel. The characters are truly young, Mary is a strong match for Byron, Claire is juvenile and a tad annoying, Polidori is a convincing beaten-down sycophant... all are beautiful, curious, and decadent... not the frightening wrecks they are in Gothic.<br /><br />Gothic works as an independent piece of shock film, and I loved it for different reasons, but this works like a Merchant and Ivory film, and was from my readings the best capture of what the summer must have felt like. Romantic, yes, but completely rekindles my interest in the lives of Shelley and Byron every time I think about the film. One of my all-time favorites.',\n",
              "       b\"This is the most depressing film I have ever seen. I first saw it as a child and even thinking about it now really upsets me. I know it was set in a time when life was hard and I know these people were poor and the crops were vital. Yes, I get all that. What I find hard to take is I can't remember one single light moment in the entire film. Maybe it was true to life, I don't know. I'm quite sure the acting was top notch and the direction and quality of filming etc etc was wonderful and I know that every film can't have a happy ending but as a family film it is dire in my opinion.<br /><br />I wouldn't recommend it to anyone who wants to be entertained by a film. I can't stress enough how this film affected me as a child. I was talking about it recently and all the sad memories came flooding back. I think it would have all but the heartless reaching for the Prozac.\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV5jSBrahB6r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "216a2d3b-9133-42cb-add3-bc7eb9474f2c"
      },
      "source": [
        "# Converting the raw text files into 20 dimensional vetors\n",
        "hub_layer(train_examples[:3])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=313, shape=(3, 20), dtype=float32, numpy=\n",
              "array([[ 2.2488396 , -1.4537774 ,  1.97866   , -0.73290443, -2.2218246 ,\n",
              "        -4.054772  , -1.6585274 ,  1.8872426 ,  1.8315402 ,  0.45302168,\n",
              "        -0.50105846,  1.3690453 , -1.9862492 ,  0.4043505 , -5.337918  ,\n",
              "         1.5515825 ,  3.6844683 , -3.3751655 , -3.4578393 , -1.1764543 ],\n",
              "       [ 3.0298512 , -3.1155329 ,  3.231569  , -2.470162  , -3.6778672 ,\n",
              "        -2.7249148 , -1.5884265 ,  0.8121041 ,  4.3448696 , -1.4254425 ,\n",
              "        -1.9567002 ,  0.7446213 , -0.9539236 ,  0.4037092 , -4.982661  ,\n",
              "         0.9707939 ,  3.717819  , -1.3615017 , -2.881222  , -1.2961531 ],\n",
              "       [ 3.041689  , -4.7446456 ,  4.733248  ,  0.30785134, -6.9846196 ,\n",
              "        -5.9006767 , -4.4500394 ,  2.3718796 ,  5.0403566 ,  0.4119934 ,\n",
              "        -2.8661985 ,  0.6986558 ,  0.5313177 ,  1.4525845 , -7.200312  ,\n",
              "         2.9011002 ,  6.392641  , -2.6039283 , -2.9440727 , -2.4246173 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY6YrUj9TfIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "7f969801-317a-4ddb-f251-d4372a12590a"
      },
      "source": [
        "# Build the network with the hub layer and adding 16 hidden layer and one output layer since binary classification\n",
        "model = tf.keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7fea705fff98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7fea705fff98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7fea705fff98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 20)                400020    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                336       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 400,373\n",
            "Trainable params: 400,373\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2thsTZxUOWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile network \n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkWGGCM_h5FU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into 10000 samples for validation and remaining 15000 samples for train set\n",
        "x_val = train_examples[:10000]\n",
        "partial_x_train = train_examples[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPgUwBG-VvGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee9c13d1-5c1d-4361-b540-60812bfda1c0"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "WARNING:tensorflow:From /tensorflow-2.0.0-rc0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-2.0.0-rc0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fea70133e18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fea70133e18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fea70133e18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "15000/15000 [==============================] - 3s 227us/sample - loss: 1.1375 - accuracy: 0.5123 - val_loss: 0.7772 - val_accuracy: 0.5691\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 3s 169us/sample - loss: 0.7444 - accuracy: 0.5630 - val_loss: 0.6908 - val_accuracy: 0.5897\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 3s 171us/sample - loss: 0.6806 - accuracy: 0.6013 - val_loss: 0.6508 - val_accuracy: 0.6270\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 3s 169us/sample - loss: 0.6425 - accuracy: 0.6361 - val_loss: 0.6215 - val_accuracy: 0.6574\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 3s 170us/sample - loss: 0.6108 - accuracy: 0.6663 - val_loss: 0.5955 - val_accuracy: 0.6777\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 3s 169us/sample - loss: 0.5807 - accuracy: 0.6958 - val_loss: 0.5706 - val_accuracy: 0.7042\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 3s 170us/sample - loss: 0.5516 - accuracy: 0.7233 - val_loss: 0.5438 - val_accuracy: 0.7313\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 3s 172us/sample - loss: 0.5211 - accuracy: 0.7504 - val_loss: 0.5170 - val_accuracy: 0.7546\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 3s 176us/sample - loss: 0.4895 - accuracy: 0.7759 - val_loss: 0.4908 - val_accuracy: 0.7703\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 3s 174us/sample - loss: 0.4567 - accuracy: 0.7969 - val_loss: 0.4617 - val_accuracy: 0.7927\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 3s 170us/sample - loss: 0.4243 - accuracy: 0.8168 - val_loss: 0.4366 - val_accuracy: 0.8065\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 3s 175us/sample - loss: 0.3944 - accuracy: 0.8361 - val_loss: 0.4134 - val_accuracy: 0.8214\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 3s 177us/sample - loss: 0.3670 - accuracy: 0.8510 - val_loss: 0.3937 - val_accuracy: 0.8315\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 3s 174us/sample - loss: 0.3417 - accuracy: 0.8630 - val_loss: 0.3764 - val_accuracy: 0.8393\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 3s 170us/sample - loss: 0.3189 - accuracy: 0.8739 - val_loss: 0.3614 - val_accuracy: 0.8461\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 3s 173us/sample - loss: 0.2980 - accuracy: 0.8823 - val_loss: 0.3489 - val_accuracy: 0.8527\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 3s 172us/sample - loss: 0.2783 - accuracy: 0.8931 - val_loss: 0.3394 - val_accuracy: 0.8550\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 3s 173us/sample - loss: 0.2607 - accuracy: 0.9015 - val_loss: 0.3296 - val_accuracy: 0.8599\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 3s 170us/sample - loss: 0.2448 - accuracy: 0.9097 - val_loss: 0.3226 - val_accuracy: 0.8621\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 3s 171us/sample - loss: 0.2293 - accuracy: 0.9156 - val_loss: 0.3170 - val_accuracy: 0.8656\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 3s 173us/sample - loss: 0.2152 - accuracy: 0.9209 - val_loss: 0.3108 - val_accuracy: 0.8690\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 3s 172us/sample - loss: 0.2031 - accuracy: 0.9274 - val_loss: 0.3071 - val_accuracy: 0.8705\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 3s 172us/sample - loss: 0.1910 - accuracy: 0.9323 - val_loss: 0.3050 - val_accuracy: 0.8714\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 3s 173us/sample - loss: 0.1793 - accuracy: 0.9377 - val_loss: 0.3031 - val_accuracy: 0.8721\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 3s 174us/sample - loss: 0.1690 - accuracy: 0.9433 - val_loss: 0.3008 - val_accuracy: 0.8739\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 3s 172us/sample - loss: 0.1596 - accuracy: 0.9467 - val_loss: 0.3002 - val_accuracy: 0.8739\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 3s 170us/sample - loss: 0.1498 - accuracy: 0.9521 - val_loss: 0.3011 - val_accuracy: 0.8752\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 3s 172us/sample - loss: 0.1411 - accuracy: 0.9550 - val_loss: 0.3012 - val_accuracy: 0.8754\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 3s 172us/sample - loss: 0.1330 - accuracy: 0.9594 - val_loss: 0.3028 - val_accuracy: 0.8759\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 3s 169us/sample - loss: 0.1255 - accuracy: 0.9626 - val_loss: 0.3046 - val_accuracy: 0.8757\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 3s 174us/sample - loss: 0.1179 - accuracy: 0.9661 - val_loss: 0.3084 - val_accuracy: 0.8757\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 3s 172us/sample - loss: 0.1112 - accuracy: 0.9690 - val_loss: 0.3130 - val_accuracy: 0.8739\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 3s 175us/sample - loss: 0.1049 - accuracy: 0.9715 - val_loss: 0.3135 - val_accuracy: 0.8753\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 3s 171us/sample - loss: 0.0983 - accuracy: 0.9739 - val_loss: 0.3185 - val_accuracy: 0.8749\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 3s 175us/sample - loss: 0.0926 - accuracy: 0.9765 - val_loss: 0.3221 - val_accuracy: 0.8748\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 3s 176us/sample - loss: 0.0871 - accuracy: 0.9783 - val_loss: 0.3282 - val_accuracy: 0.8744\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 3s 173us/sample - loss: 0.0823 - accuracy: 0.9804 - val_loss: 0.3324 - val_accuracy: 0.8744\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 3s 175us/sample - loss: 0.0772 - accuracy: 0.9829 - val_loss: 0.3352 - val_accuracy: 0.8741\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 3s 173us/sample - loss: 0.0726 - accuracy: 0.9842 - val_loss: 0.3407 - val_accuracy: 0.8737\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 3s 175us/sample - loss: 0.0683 - accuracy: 0.9864 - val_loss: 0.3451 - val_accuracy: 0.8730\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebd5SZZiWKpx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "389c091a-752f-4a29-896b-ea09daccb70c"
      },
      "source": [
        "# Evaluate the model \n",
        "results = model.evaluate(test_data, test_labels, verbose=0)\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(\"%s: %.3f\" % (name, value))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.368\n",
            "accuracy: 0.861\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}