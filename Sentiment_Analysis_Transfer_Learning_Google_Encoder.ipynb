{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_Transfer_Learning_Google_Encoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p46w1uzgM8t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6d922126-7239-4a4c-b8f0-b081701aee7c"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version:  2.0.0-rc0\n",
            "Eager mode:  True\n",
            "Hub version:  0.6.0\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXCw_fAgSbyX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "427f064b-6ce9-41a3-a106-867e1b95e380"
      },
      "source": [
        "train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], \n",
        "                                  batch_size=-1, as_supervised=True)\n",
        "\n",
        "train_examples, train_labels = tfds.as_numpy(train_data)\n",
        "test_examples, test_labels = tfds.as_numpy(test_data)\n",
        "\n",
        "# /Users/jheaton/tensorflow_datasets/imdb_reviews/plain_text/0.1.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(), dtype=tf.string),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(), dtype=tf.string),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(), dtype=tf.string),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(), dtype=tf.string),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(), dtype=tf.string),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(), dtype=tf.string),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4rvJNjceZJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
        "hub_layer = hub.KerasLayer(model, output_shape=[20], input_shape=[], \n",
        "                           dtype=tf.string, trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5K1GctYg82x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9df85915-664d-45cc-cab6-85d32bdfadab"
      },
      "source": [
        "train_examples[:3]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'I have no idea what the other reviewer is talking about- this was a wonderful movie, and created a sense of the era that feels like time travel. The characters are truly young, Mary is a strong match for Byron, Claire is juvenile and a tad annoying, Polidori is a convincing beaten-down sycophant... all are beautiful, curious, and decadent... not the frightening wrecks they are in Gothic.<br /><br />Gothic works as an independent piece of shock film, and I loved it for different reasons, but this works like a Merchant and Ivory film, and was from my readings the best capture of what the summer must have felt like. Romantic, yes, but completely rekindles my interest in the lives of Shelley and Byron every time I think about the film. One of my all-time favorites.',\n",
              "       b'This was a wonderfully clever and entertaining movie that I shall never tire of watching many, many times. The casting was magnificent in matching up the young with the older characters. There are those of us out here who really do appreciate good actors and an intelligent story format. As for Judi Dench, she is beautiful and a gift to any kind of production in which she stars. I always make a point to see Judi Dench in all her performances. She is a superb actress and a pleasure to watch as each transformation of her character comes to life. I can only be grateful when I see such an outstanding picture for most of the motion pictures made more recently lack good characters, good scripts and good acting. The movie public needs heroes, not deviant manikins, who lack ingenuity and talent. How wonderful to see old favorites like Leslie Caron, Olympia Dukakis and Cleo Laine. I would like to see this movie win the awards it deserves. Thank you again for a tremendous night of entertainment. I congratulate the writer, director, producer, and all those who did such a fine job.',\n",
              "       b\"This was soul-provoking! I am an Iranian, and living in th 21st century, I didn't know that such big tribes have been living in such conditions at the time of my grandfather!<br /><br />You see that today, or even in 1925, on one side of the world a lady or a baby could have everything served for him or her clean and on-demand, but here 80 years ago, people ventured their life to go to somewhere with more grass. It's really interesting that these Persians bear those difficulties to find pasture for their sheep, but they lose many the sheep on their way.<br /><br />I praise the Americans who accompanied this tribe, they were as tough as Bakhtiari people.\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw2QOPktS2lC",
        "colab_type": "text"
      },
      "source": [
        "%% **Loading the pretrained Google \"gnews\" model which will convert the raw data into 20 dimensional vector **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqCs0rVtSkGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
        "hub_layer = hub.KerasLayer(model, output_shape=[20], input_shape=[], \n",
        "                           dtype=tf.string, trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljlu8lo4TRBP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "8bef12bb-a4dd-4657-d9f3-0c14aa3c0c89"
      },
      "source": [
        "# Raw training data of the movie review  \n",
        "train_examples[:3]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'I have no idea what the other reviewer is talking about- this was a wonderful movie, and created a sense of the era that feels like time travel. The characters are truly young, Mary is a strong match for Byron, Claire is juvenile and a tad annoying, Polidori is a convincing beaten-down sycophant... all are beautiful, curious, and decadent... not the frightening wrecks they are in Gothic.<br /><br />Gothic works as an independent piece of shock film, and I loved it for different reasons, but this works like a Merchant and Ivory film, and was from my readings the best capture of what the summer must have felt like. Romantic, yes, but completely rekindles my interest in the lives of Shelley and Byron every time I think about the film. One of my all-time favorites.',\n",
              "       b'This was a wonderfully clever and entertaining movie that I shall never tire of watching many, many times. The casting was magnificent in matching up the young with the older characters. There are those of us out here who really do appreciate good actors and an intelligent story format. As for Judi Dench, she is beautiful and a gift to any kind of production in which she stars. I always make a point to see Judi Dench in all her performances. She is a superb actress and a pleasure to watch as each transformation of her character comes to life. I can only be grateful when I see such an outstanding picture for most of the motion pictures made more recently lack good characters, good scripts and good acting. The movie public needs heroes, not deviant manikins, who lack ingenuity and talent. How wonderful to see old favorites like Leslie Caron, Olympia Dukakis and Cleo Laine. I would like to see this movie win the awards it deserves. Thank you again for a tremendous night of entertainment. I congratulate the writer, director, producer, and all those who did such a fine job.',\n",
              "       b\"This was soul-provoking! I am an Iranian, and living in th 21st century, I didn't know that such big tribes have been living in such conditions at the time of my grandfather!<br /><br />You see that today, or even in 1925, on one side of the world a lady or a baby could have everything served for him or her clean and on-demand, but here 80 years ago, people ventured their life to go to somewhere with more grass. It's really interesting that these Persians bear those difficulties to find pasture for their sheep, but they lose many the sheep on their way.<br /><br />I praise the Americans who accompanied this tribe, they were as tough as Bakhtiari people.\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV5jSBrahB6r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "6e00d637-dc01-4c3c-d3ad-0e7f028eaa7b"
      },
      "source": [
        "# Converting the raw text files into 20 dimensional vetors\n",
        "hub_layer(train_examples[:3])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=496, shape=(3, 20), dtype=float32, numpy=\n",
              "array([[ 3.0298512 , -3.1155329 ,  3.231569  , -2.470162  , -3.6778672 ,\n",
              "        -2.7249148 , -1.5884265 ,  0.8121041 ,  4.3448696 , -1.4254425 ,\n",
              "        -1.9567002 ,  0.7446213 , -0.9539236 ,  0.4037092 , -4.982661  ,\n",
              "         0.9707939 ,  3.717819  , -1.3615017 , -2.881222  , -1.2961531 ],\n",
              "       [ 3.9022908 , -5.336768  ,  4.6433706 , -2.322609  , -5.6409845 ,\n",
              "        -2.2914128 , -1.3552328 ,  1.1260422 ,  4.928207  , -1.4990277 ,\n",
              "        -3.5764084 ,  0.8652999 , -1.8267108 ,  0.7212572 , -6.1661105 ,\n",
              "        -0.67619115,  5.83987   , -2.078528  , -3.7790735 , -2.0113754 ],\n",
              "       [ 2.2488396 , -1.4537774 ,  1.97866   , -0.73290443, -2.2218246 ,\n",
              "        -4.054772  , -1.6585274 ,  1.8872426 ,  1.8315402 ,  0.45302168,\n",
              "        -0.50105846,  1.3690453 , -1.9862492 ,  0.4043505 , -5.337918  ,\n",
              "         1.5515825 ,  3.6844683 , -3.3751655 , -3.4578393 , -1.1764543 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY6YrUj9TfIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "0bce5f2c-fb0e-4fbe-98d5-e57a479d0eb7"
      },
      "source": [
        "# Build the network with the hub layer and adding 16 hidden layer and one output layer since binary classification\n",
        "model = tf.keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7faba0526320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7faba0526320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7faba0526320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_1 (KerasLayer)   (None, 20)                400020    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                336       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 400,373\n",
            "Trainable params: 400,373\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2thsTZxUOWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile network \n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkWGGCM_h5FU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into 10000 samples for validation and remaining 15000 samples for train set\n",
        "x_val = train_examples[:10000]\n",
        "partial_x_train = train_examples[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPgUwBG-VvGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71af3551-90ba-42b4-e1bc-497add0ee7cb"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "WARNING:tensorflow:From /tensorflow-2.0.0-rc0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-2.0.0-rc0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fab5d6029d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fab5d6029d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fab5d6029d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "15000/15000 [==============================] - 4s 235us/sample - loss: 0.7878 - accuracy: 0.5608 - val_loss: 0.6961 - val_accuracy: 0.6032\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 3s 168us/sample - loss: 0.6662 - accuracy: 0.6219 - val_loss: 0.6170 - val_accuracy: 0.6691\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 3s 171us/sample - loss: 0.5905 - accuracy: 0.6941 - val_loss: 0.5692 - val_accuracy: 0.7139\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 3s 177us/sample - loss: 0.5447 - accuracy: 0.7415 - val_loss: 0.5339 - val_accuracy: 0.7498\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 3s 180us/sample - loss: 0.5055 - accuracy: 0.7732 - val_loss: 0.5034 - val_accuracy: 0.7712\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 3s 176us/sample - loss: 0.4698 - accuracy: 0.7972 - val_loss: 0.4746 - val_accuracy: 0.7877\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 3s 174us/sample - loss: 0.4353 - accuracy: 0.8165 - val_loss: 0.4479 - val_accuracy: 0.8018\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 3s 170us/sample - loss: 0.4031 - accuracy: 0.8358 - val_loss: 0.4249 - val_accuracy: 0.8134\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 3s 169us/sample - loss: 0.3736 - accuracy: 0.8501 - val_loss: 0.4037 - val_accuracy: 0.8237\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 3s 174us/sample - loss: 0.3469 - accuracy: 0.8638 - val_loss: 0.3849 - val_accuracy: 0.8318\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 3s 176us/sample - loss: 0.3198 - accuracy: 0.8753 - val_loss: 0.3656 - val_accuracy: 0.8457\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 3s 172us/sample - loss: 0.2967 - accuracy: 0.8868 - val_loss: 0.3512 - val_accuracy: 0.8515\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 3s 172us/sample - loss: 0.2759 - accuracy: 0.8963 - val_loss: 0.3389 - val_accuracy: 0.8575\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 3s 174us/sample - loss: 0.2573 - accuracy: 0.9031 - val_loss: 0.3294 - val_accuracy: 0.8620\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 3s 174us/sample - loss: 0.2397 - accuracy: 0.9118 - val_loss: 0.3205 - val_accuracy: 0.8644\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 3s 171us/sample - loss: 0.2246 - accuracy: 0.9178 - val_loss: 0.3170 - val_accuracy: 0.8651\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 3s 173us/sample - loss: 0.2091 - accuracy: 0.9262 - val_loss: 0.3098 - val_accuracy: 0.8697\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 3s 174us/sample - loss: 0.1955 - accuracy: 0.9315 - val_loss: 0.3033 - val_accuracy: 0.8736\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 3s 173us/sample - loss: 0.1831 - accuracy: 0.9372 - val_loss: 0.3004 - val_accuracy: 0.8742\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 3s 171us/sample - loss: 0.1718 - accuracy: 0.9439 - val_loss: 0.2991 - val_accuracy: 0.8741\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 3s 175us/sample - loss: 0.1615 - accuracy: 0.9473 - val_loss: 0.2978 - val_accuracy: 0.8761\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 3s 174us/sample - loss: 0.1514 - accuracy: 0.9537 - val_loss: 0.2960 - val_accuracy: 0.8780\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 3s 172us/sample - loss: 0.1421 - accuracy: 0.9566 - val_loss: 0.3012 - val_accuracy: 0.8746\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 3s 172us/sample - loss: 0.1336 - accuracy: 0.9601 - val_loss: 0.2995 - val_accuracy: 0.8773\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 3s 173us/sample - loss: 0.1260 - accuracy: 0.9633 - val_loss: 0.3034 - val_accuracy: 0.8760\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 3s 176us/sample - loss: 0.1181 - accuracy: 0.9665 - val_loss: 0.3019 - val_accuracy: 0.8770\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 3s 173us/sample - loss: 0.1100 - accuracy: 0.9700 - val_loss: 0.3025 - val_accuracy: 0.8795\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 3s 179us/sample - loss: 0.1040 - accuracy: 0.9723 - val_loss: 0.3061 - val_accuracy: 0.8777\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 3s 176us/sample - loss: 0.0966 - accuracy: 0.9760 - val_loss: 0.3093 - val_accuracy: 0.8780\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 3s 175us/sample - loss: 0.0906 - accuracy: 0.9781 - val_loss: 0.3120 - val_accuracy: 0.8789\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 3s 172us/sample - loss: 0.0851 - accuracy: 0.9802 - val_loss: 0.3158 - val_accuracy: 0.8775\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 3s 175us/sample - loss: 0.0796 - accuracy: 0.9827 - val_loss: 0.3234 - val_accuracy: 0.8745\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 3s 173us/sample - loss: 0.0746 - accuracy: 0.9845 - val_loss: 0.3266 - val_accuracy: 0.8754\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 3s 176us/sample - loss: 0.0695 - accuracy: 0.9863 - val_loss: 0.3297 - val_accuracy: 0.8743\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 3s 172us/sample - loss: 0.0655 - accuracy: 0.9880 - val_loss: 0.3356 - val_accuracy: 0.8743\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 3s 175us/sample - loss: 0.0607 - accuracy: 0.9894 - val_loss: 0.3407 - val_accuracy: 0.8746\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 3s 175us/sample - loss: 0.0568 - accuracy: 0.9910 - val_loss: 0.3464 - val_accuracy: 0.8736\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 3s 174us/sample - loss: 0.0532 - accuracy: 0.9918 - val_loss: 0.3526 - val_accuracy: 0.8726\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 3s 174us/sample - loss: 0.0495 - accuracy: 0.9927 - val_loss: 0.3595 - val_accuracy: 0.8717\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 3s 175us/sample - loss: 0.0463 - accuracy: 0.9935 - val_loss: 0.3649 - val_accuracy: 0.8708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebd5SZZiWKpx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9e6fa009-50d3-48ec-b3a1-56b388cf0369"
      },
      "source": [
        "# Evaluate the model \n",
        "results = model.evaluate(test_data, test_labels, verbose=0)\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(\"%s: %.3f\" % (name, value))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.402\n",
            "accuracy: 0.857\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}